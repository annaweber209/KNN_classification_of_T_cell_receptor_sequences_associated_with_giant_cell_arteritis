{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from collections import Counter\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these so that basefolder is the folder containing the raw data folder\n",
    "# and outfolder being the folder to save the cleaned data in\n",
    "basefolder = ''\n",
    "outfolder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_NN_dist(test_seq, reference_df, column):\n",
    "    reference_df['dist'] = reference_df[column].apply(lambda x: levenshtein_distance(x, test_seq))\n",
    "    NNdist = min(reference_df['dist'])\n",
    "    return NNdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCA_gDNA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wbr/opt/anaconda3/envs/leeds/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/wbr/opt/anaconda3/envs/leeds/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Find all sequencing errors\n",
    "read_limit = 10\n",
    "to_trash=pd.DataFrame() # Dataframe to collect sequences that will be excluded\n",
    "overlapping_clones = pd.DataFrame()\n",
    "for folder in ['GCA_gDNA']:#, 'Agematched Controls', 'other Controls']: #'GCA_FFPE', \n",
    "    print(folder)\n",
    "    # Find all files with name pattern _clones_inclNN.txt in folder\n",
    "    for filename in glob.glob(os.path.join(basefolder, 'raw data', folder, '*_clones_inclNN.txt')):\n",
    "        sample = pd.read_csv(\n",
    "                filename,\n",
    "                delimiter='\\t',\n",
    "                usecols=['cloneCount', 'cloneFraction', 'aaSeqCDR3','nSeqCDR3', 'bestVHit', 'bestJHit']\n",
    "            )\n",
    "        # Extract patient id from filename\n",
    "        sample['Name'] = [filename.split('/')[-1].split('_')[0] for i in range(len(sample))]\n",
    "        # Remove all singletons and doubles\n",
    "        sample = sample[sample['cloneCount'] >= 2]\n",
    "        # Remove seqs with less than 10 reads if they are only one nucleotide away from another seq\n",
    "        pot_errors = sample[sample['cloneCount'] <= read_limit]\n",
    "        ref = sample[sample['cloneCount'] > read_limit]\n",
    "        # find distance to closest neighbor in higher read category\n",
    "        pot_errors['NNdist'] = pot_errors['nSeqCDR3'].apply(lambda x: find_NN_dist(x, ref, 'nSeqCDR3'))\n",
    "        # find those with less than 2 nucleotides distance\n",
    "        pot_errors = pot_errors[pot_errors['NNdist'] < 2]\n",
    "        # save to trash later\n",
    "        to_trash = pd.concat([to_trash, pot_errors])\n",
    "        # add all clones in the sample as potentially overlapping clones\n",
    "        overlapping_clones = pd.concat(\n",
    "                        [overlapping_clones, sample],\n",
    "                        ignore_index=True\n",
    "                    )\n",
    "    \n",
    "    count_dict = Counter(overlapping_clones['nSeqCDR3'])\n",
    "    # exclude all clones that occur only once (these dont overlap between at least 2 patients)\n",
    "    exclude1 = [x for x in count_dict if count_dict[x] < 2]\n",
    "    # result is a dataframe with all clones that appear in at least two patients\n",
    "    overlapping_clones = overlapping_clones[~overlapping_clones['nSeqCDR3'].isin(exclude1)]\n",
    "\n",
    "to_trash_RE = to_trash.dropna(subset=['NNdist'])\n",
    "to_trash_RE.to_csv(os.path.join(basefolder, 'to_trash_sequencing_errors.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wbr/opt/anaconda3/envs/leeds/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### Find all Sequence Sharing Artifacts Cohort-Wise (Only GCA data)\n",
    "# uncomment one of the sections below\n",
    "\n",
    "### Cohort definitions for gDNA samples\n",
    "### set Cohort = 0 for controls, 1 for cohort 1 GCA data, 2 for cohort 2 GCA data\n",
    "\n",
    "'''\n",
    "overlapping_clones['Cohort'] = [2 if 'gDNA' in x else 0 for x in overlapping_clones['Name']]\n",
    "cohort1 = ['14907-gDNA','14915-gDNA','14914-gDNA','14910-gDNA','14922-gDNA',\n",
    "'14912-gDNA','14927-gDNA','14930-gDNA','14929-gDNA','14931-gDNA','14926-gDNA',\n",
    "'16094-gDNA','12898-gDNA','12849-gDNA','12902-gDNA','12835-gDNA','12223-gDNA',\n",
    "'11037-gDNA','12954-gDNA','15272-gDNA','15429-gDNA','15456-gDNA','15518-gDNA','15576-gDNA','15579-gDNA']\n",
    "overlapping_clones['Cohort'] = [x['Cohort'] if x['Name'] not in cohort1 else 1 for i,x in overlapping_clones.iterrows()]\n",
    "'''\n",
    "### Cohort definitions for FFPE samples\n",
    "### set Cohort = 0 for controls, 1 for cohort 1 GCA data, 2 for cohort 2 GCA data\n",
    "'''\n",
    "overlapping_clones['Cohort'] = [2 if 'FFPE' in x else 0 for x in overlapping_clones['Name']]\n",
    "cohort1 = ['14907-FFPE','14915-FFPE','14914-FFPE','14910-FFPE','14922-FFPE',\n",
    "'14912-FFPE','14927-FFPE','14930-FFPE','14929-FFPE','14931-FFPE','14926-FFPE',\n",
    "'16094-FFPE','12898-FFPE','12849-FFPE','12902-FFPE','12835-FFPE','12223-FFPE',\n",
    "'11037-FFPE','12954-FFPE','15272-FFPE','15429-FFPE','15456-FFPE','15518-FFPE','15576-FFPE','15579-FFPE']\n",
    "overlapping_clones['Cohort'] = [x['Cohort'] if x['Name'] not in cohort1 else 1 for i,x in overlapping_clones.iterrows()]\n",
    "'''\n",
    "\n",
    "# find overlapping sequences\n",
    "to_trash_overlap = pd.DataFrame()\n",
    "\n",
    "for cohort in [0,1,2]:\n",
    "    #extract only overlapping sequences from the current cohort\n",
    "    cohort_data = overlapping_clones[overlapping_clones['Cohort'] == cohort]\n",
    "    unique_overlapping_clones = set(cohort_data['nSeqCDR3'])\n",
    "\n",
    "    for clone in unique_overlapping_clones:\n",
    "        # find all instances of a clone\n",
    "        subset = cohort_data[cohort_data['nSeqCDR3'] == clone]\n",
    "        # calculate expansion in relation to largest expanded occurences of that clone\n",
    "        largest_clone = np.max(subset['cloneCount'])\n",
    "        subset['fraction'] = [x/largest_clone for x in subset['cloneCount']]\n",
    "        # remove seq if identical NN seq in other sample with higher clone count (fraction  < 0.1 )\n",
    "        to_trash_overlap = pd.concat([to_trash_overlap, subset[subset['fraction'] < 0.01]])\n",
    "\n",
    "to_trash = pd.concat([to_trash_overlap, to_trash_RE])\n",
    "to_trash['UI'] = [x['nSeqCDR3']+str(x['cloneCount']) for i,x in to_trash.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Go through data again, trash all the trash and save new files\n",
    "for folder in ['GCA_gDNA', 'Agematched Controls', 'other Controls']: #'GCA_FFPE'\n",
    "    #print(folder)\n",
    "    for filename in glob.glob(os.path.join(basefolder, 'raw data', folder, '*_clones_inclNN.txt')):\n",
    "        #print(filename)\n",
    "        sample = pd.read_csv(\n",
    "                filename,\n",
    "                delimiter='\\t',\n",
    "                usecols=['cloneCount', 'cloneFraction', 'aaSeqCDR3','nSeqCDR3', 'bestVHit', 'bestJHit']\n",
    "            )\n",
    "        name = filename.split('/')[-1].split('_')[0]\n",
    "        # Retain only sequences with count of at least 2\n",
    "        sample = sample[sample['cloneCount'] >= 2]\n",
    "        sample['UI'] = [x['nSeqCDR3']+str(x['cloneCount']) for i,x in sample.iterrows()]\n",
    "        # remove everything that we identified as trash before\n",
    "        trash_nseqs = to_trash[to_trash['Name'] == name]['UI']\n",
    "        sample = sample[~sample['UI'].isin(trash_nseqs)]\n",
    "        sample = sample.drop(columns=['UI'])\n",
    "        # save clean data\n",
    "        #sample.to_csv(os.path.join(outfolder, name+'_cleaned_2.txt'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leeds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "093c904bb1fe10834720fbe7bdbb915e23f0cbf4766aabe47c881e70eb996a07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
